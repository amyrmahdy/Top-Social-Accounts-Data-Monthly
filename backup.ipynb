{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import github\n",
    "\n",
    "# Function to scrape data from socialblade.com\n",
    "def scrape_socialblade(url, platform):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the table containing the data\n",
    "    table = soup.find('table', {'class': 'sortable-table'})\n",
    "\n",
    "    # Extract the table headers\n",
    "    headers = [header.text.strip() for header in table.find_all('th')]\n",
    "\n",
    "    # Extract the table rows\n",
    "    rows = table.find_all('tr')[1:]\n",
    "\n",
    "    # Initialize an empty list to store the data\n",
    "    data = []\n",
    "\n",
    "    # Extract the data from each row\n",
    "    for row in rows:\n",
    "        data.append([cell.text.strip() for cell in row.find_all('td')])\n",
    "\n",
    "    # Create a Pandas DataFrame from the data\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    # Generate a unique filename based on the current date and time\n",
    "    now = datetime.datetime.now()\n",
    "    filename = f\"{now.strftime('%Y-%m')}/{platform}_top_50_{now.strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n",
    "\n",
    "    # Create the directories if they don't exist\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    return filename\n",
    "\n",
    "# URLs for each social media platform on socialblade.com\n",
    "urls = {\n",
    "    'tiktok': 'https://socialblade.com/tiktok/top/50/followers',\n",
    "    'youtube': 'https://socialblade.com/youtube/top/50/mostsubscribed',\n",
    "    'instagram': 'https://socialblade.com/instagram/top/50/followers',\n",
    "    'twitter': 'https://socialblade.com/twitter/top/50/followers'\n",
    "}\n",
    "\n",
    "# Scrape data for each platform\n",
    "for platform, url in urls.items():\n",
    "    filename = scrape_socialblade(url, platform)\n",
    "    print(f\"Scraped data for {platform} and saved to {filename}\")\n",
    "\n",
    "# Push the data to GitHub repository\n",
    "access_token = 'YOUR_GITHUB_ACCESS_TOKEN'\n",
    "repo_name = 'YOUR_GITHUB_REPOSITORY'\n",
    "\n",
    "# Create a GitHub instance\n",
    "gh = github.Github(access_token)\n",
    "repo = gh.get_repo(repo_name)\n",
    "\n",
    "# Commit and push the scraped data\n",
    "for platform in urls.keys():\n",
    "    # Generate the file path\n",
    "    now = datetime.datetime.now()\n",
    "    filepath = f\"{now.strftime('%Y-%m')}/{platform}_top_50_{now.strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n",
    "\n",
    "    # Read the CSV file\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Commit the file to the repository\n",
    "    repo.create_file(filepath, f\"Add {platform} top 50 data\", content)\n",
    "\n",
    "print(\"Data pushed to GitHub repository\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
